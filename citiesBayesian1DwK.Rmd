---
title: "Bayesian Cities Model 1D"
author: "Dina Sinclair"
date: '`r Sys.Date()`'
output:
  html_document: default
  pdf_document: default
---
### Overview

Imagine the following: as a policymaker, you want to implement a new program in a subset of cities. To improve your knowledge of which cities would benefit the most from the program, you have the budget to run a pilot in some of the potential city choices, but not all of them. Given that you have pre-existing beliefs (priors) on how well you think the program will fare in each city, where should you run the pilot to glean the most information?

Here, we tackle this question using a bayseian hierarchical model coded in a combination of R and Stan.

### Tools

This code is written in R 3.3.2 using [R Markdown](https://rmarkdown.rstudio.com/). The bayesian modeling is coded up in a separate language called [Stan](http://mc-stan.org/). Stan's specific tools for bayesian inference and modeling makes bayesian methods far more approachable than before. Here, we're using the rstan library to allow us to interface easily between the main R code and the bayesian Stan files.

```{r, warning = FALSE, message = FALSE}
library("rstan")
```

### Constants

Before we input data into the model, we need to set a few key constants. These are:

* *I*, the total number of cities we have priors on and are considering for the final program
* *num_pilots*, the number of cities we can run a pilot program in
* *num_final_cities*, the number of cities we can implement the final program in
* *num_hypothetical_draws*, the number of times we'll simulate the results of each potential pilot choice
* *Q*, the `quality' of the new pilot data (the factor by which the pilot data variance will differ from the original variance). A Q of 5 implies the pilot data has a variance that is 5 times smaller than the original study variance.


```{r}
# Set general constants
I <- 3 # Number of cities
num_pilots <- 2 # Number of pilots
num_final_cities <- 2 # Number of cities we can implement the final program in
num_hypothetical_draws <- 10 # Number of times you simulate pilot study results
Q <- 5 # Pilot quality (variance multiplication factor)
set.seed(17) # Ensure randomization is reproducible through a specified seed
```

### Inputs

For every city $i$, we need to know

 * A prior $Y_i$ that estimates the mean effect of the program on city $i$
 * A standard error $\sigma_i$ for each of these point estimates $Y_i$

##### Generating Example Inputs
In this model, we will be assuming that
$$Y_i \sim N(\theta_i,\sigma^2_i)$$
and
$$\theta_i \sim N(\mu,\tau^2)$$
To tell whether or not our model is accurately backing out $\mu$ and $\tau^2$, we can first pick a $\mu$ and $\tau^2$, generate input data based off of those constants, and then compare the resulting predicted $\mu$ and $\tau^2$ program results to the constants we originally selected.

```{r}
# Set model hyperparameters for data generation
mu <- 10
tauSq <- 2
```

To generate $\theta_i$, we then use the fact that $\theta_i \sim N(\mu, \tau^2)$ for all $i$. Since the $\sigma_i^2$ are independent of our choices of $\mu$ and $\tau^2$, we can use any $\sigma_i^2$ values we want for our generated input data. For simplicity, here we use values that are taken from U(0,1).

```{r}
# Generate theta and sigmaSq
theta <- rnorm(I, mean = mu, sd = sqrt(tauSq)) # with theta ~ N(mu,tauSq)
sigmaSq <- 10*runif(I) # with sigmaSq ~ U(0,1)
Y <- list(theta=theta, var=sigmaSq)
```

We can then reshape the data to a more convenient structure, where Y is a list containing all of the theta and sigmaSq values. The stan file also needs all of the data in a specific format, which we're creating here in the list basic_dat_generated.

```{r}
# Save our generated input data together in a list
basic_dat_generated <- list(I=I,Y=theta,sigmaSq=sigmaSq)

# Display what we've generated
basic_dat_generated
```


### Step 1: Calculate $\theta_i, \mu, \tau^2$ using the original priors Y

We're assuming a **random effects model**, that is that 
$$\theta_i \sim N(\mu, \tau^2)$$ 
and

$$Y_i \sim N(\theta_i, \sigma_{i}^2)$$

To make use of this assumption, we need to estimate scalars $\mu$ and $\tau^2$ along with the vector $\theta = (\theta_1,\dots,\theta_I)$. We can do this using stan! The following code calls up the stan model *randomEffectsModel1D.stan*, a separate text file. This code will be run in stan, with the parameters

* *iter*, the number of iterations TODO figure out better what this means
* *chains*, the number of chains TODO ditto

```{r}
fit <- stan(file = 'randomEffectsModel1D.stan', 
            data = basic_dat_generated, 
            iter = 1000, chains = 2)
```

Sure enough, we can see that stan did two main sets of iterations (chains) adn that each of those sets was 1000 iterations long. TODO look in more detail and link to a relevant explanation. (TODO also worth deciding - talk about the warning types here, divergent transitions and pairs() plot?)

```{r}
fit
```

Looking at the data, we can see that our random effects model has generated a value for $\mu$, $\tau$ and $\theta$. This prediction uses the NUTS model (TODO insert link). We can now update our $\theta$ values to reflect the REM results.

```{r}
# Readjust knowledge of Y based on REM
params <- extract(fit)
for (i in 1:length(Y$theta)){
  Y$theta[i] <- mean(params$theta[,i])
}
Y
```


### Step 2: Pick a subset $K$ studies to pilot, calculate $Y^P_k$

##### Theoretically

First, pick a subset of cities $K$ to update through new pilot information. For these cities, we'll assume a **fixed effects model** and draw a new sample, imagining that for city $k in K$ this is a new study $Y^P_k$ done in the same place as study $Y_k$, so we can improve on our knowledge of $Y_k$. For now we will arbitrarily decide that $\sigma^P_k = \frac 1 Q \sigma_k$. So for $k\in K$,

$$ Y^P_k \sim N(\theta_k, \frac 1 Q \sigma_k)$$
To do this, we'll use the following function:
```{r}
# Calculate new data for all K new pilots
get_pilot_results <- function(K,Y){
  # Before update, Y_P is the same as Y
  Y_P <- Y
  
  # Update for each new pilot k
  for (k in K){
    
    # Gather New Pilot Data
    new_sigmaSq <- Y$var[k] * (1/Q)
    new_mean <- rnorm( 1 , mean = Y$theta[k] , sd = sqrt(new_sigmaSq ))
    
    # Combine the old and new data 
    post_pilot <- update_Y(Y$theta[k],new_mean,Y$var[k],new_sigmaSq)
    Y_P$theta[k] <- post_pilot$theta
    Y_P$var[k] <- post_pilot$var
    return(Y_P)
  }
}
```

### Step 3: Update all $Y$ values to get $Y'$

Once those $k$ new values get calculated, update by combining to get 
$$update(Y_k, Y^P_k) = Y'_k$$

This draws on the idea that the mean can be combined with the equation
$$ \mu' = \frac{\mu_2 \sigma_1^2 + \sigma_2^2 \mu_1}{\sigma_2^2 + \sigma_1^2}$$
and variance can be combined using
$$\sigma' = \frac{\sigma_1^2 \sigma_2^2}{\sigma_1^2+\sigma_2^2} = \frac{1}{\frac{1}{\sigma_2^2}+\frac{1}{\sigma_1^2}}$$

Concretely, this code looks like

```{r}
update_Y <- function(mu1, mu2, sigSq1, sigSq2){
  update_mu <- (mu1*sigSq2 + mu2*sigSq1)/(sigSq1 + sigSq2)
  update_sigSq <- (sigSq1*sigSq2)/(sigSq1 + sigSq2)
  return(list(theta = update_mu, var = update_sigSq))
}
```


### Step 4: Use $Y'$ to get final $\theta'$

Once we have all the updated $Y'_i$ we can use them to get $\theta'_i$ based off of $\mu', \tau'^{2}$ with $Y' \sim N(\theta'_i, \sigma'_{i})$, using the same randomEffectsModel1D.stan file as before. We can extract that fit as fit_updated, and use it to get the needed $\theta'$.

Once we update $\theta$ to $\theta'$, we can look at the ranking of this end result - with our new knowledge, which cities do the best? Using the order function, we can rank the cities from best (highest value for $\theta'$) to worst (lowest value for $\theta'$). The new ranking is returned in the function below.

```{r}
new_ranking <- function(fit_updated,Y_P) {
  params_updated <- extract(fit_updated)
  Y_updated <- Y_P
  for (i in 1:length(Y_updated$theta)){
    Y_updated$theta[i] <- mean(params_updated$theta[,i])
  }
  new_rank <- order(Y_updated$theta, decreasing=TRUE)
  return(new_rank)
}
```

Once we have this ranking, we next need to ask - did the information from the pilots add value? In this case, we're choosing to define the pilot information as valuable if the act of running the pilot studies changes which subset of cities we select for the final program implementation. 

In other words, we are looking at if the pilots *change our mind*. This happens when the cities that have the highest num_final values of $\theta'$ are different than the cities that originally had the highest num_final values of our initial $\theta$ priors.

This function returns a boolean denoting if for a given subset of cities $K$ to run pilots in, we will change our mind as a result. Note that this relies on whatever draws happen in this specific instance of the pilot simulation, so for each given subset of cities $K$, there is some probability that 
```{r}
change_mind <- function(K,Y,original_rank){
  Y_P <- get_pilot_results(K,Y)
  updated_dat_generated <- list(I, Y=Y_P$theta, sigmaSq=Y_P$var)
  fit_updated <- stan(file = 'randomEffectsModel1D.stan', 
                      data = updated_dat_generated, 
                      iter = 1000, chains = 2)
  new_rank <- new_ranking(fit_updated,Y_P) 
  print(new_rank)
  return(!setequal(original_rank[1:num_final_cities],new_rank[1:num_final_cities]))
}
```


```{r, results="hide", warning = FALSE}
original_rank <- order(Y$theta, decreasing=TRUE)
original_rank
combinations <-combn(seq(I),num_pilots)
nmc <- numeric(I)
for (i in 1:ncol(combinations)){
  for (j in 1:num_hypothetical_draws){
    K <- combinations[,i]
    nmc[i] <- nmc[i] + change_mind(K,Y,original_rank)
  }
} 
nmc
```


Brief summary of the results
```{r}
# So what are these results exactly?
print(Y)
for (i in 1:length(nmc)){
  print(combinations[,i])
  print(paste("Number of times minds changed: ",nmc[i],"/",num_hypothetical_draws))
} 

```


