---
title: "Bayesian Cities Model 1D"
author: "Dina Sinclair"
date: '`r Sys.Date()`'
output:
  html_document: default
  pdf_document: default
---

```{r, warning = FALSE, message = FALSE}
library("rstan")
```

### Inputs

##### Notation
Given

$$Y = (Y_1, \dots, Y_i) $$
where each $Y_i$ has its own given $\sigma_{i}$,assume $Y \sim N(\theta_i, \sigma_{i}^2)$.

We won't be looking at the individual data in any study, so we'll essentially be assuming that the sample size for every study $J = 1$. $Y_i$ is the *point estimation*, the mean of the study, and $\sigma_i$ is that study's variance. 

##### Arbitrary Example Inputs
For now, we'll use that classic arbitrary dataset I've been using
We'll hope that we can recover mu and tauSq correctly!
```{r}
# Set input parameters
set.seed(17)
mu <- 10
tauSq <- 2

# Set general constants
C <- 2 # Number of pilots we can run
D <- 2 # Number of cities we can implement the final program in
I <- 3 # Number of studies (AKA number of cities)
J <- 1 # Number of data points per study (Currently setting this to 1 for simplicity)
num_hypothetical_draws <- 15 # Number of times you draw new pretend pilot study results

# Generate theta and sigmaSq based off of mu, tau, I, J
sigmaSq <- 10*runif(I) # For now, all sigma are ~U(0,1)
theta <- rnorm(I, mu, tauSq) # and theta ~N(mu,tauSq)
sigmaSq <- matrix(sigmaSq, I , J)
theta <- matrix(theta, I , J)

# Calculate and reshape Y
Y <- list(mu=theta, sd=sigmaSq)

# Save our input data together in a list
basic_dat_generated <- list(J=J,I=I,Y=theta,sigmaSq=sigmaSq)

# Display what we've generated
basic_dat_generated
```

### Step 1: Calculate $\theta_i, \mu, \tau^2$ using the original priors Y

We're assuming a **random effects model**, that is that $$\theta_i \sim N(\mu, \tau^2) \text{ and } Y_i \sim N(\theta_i, \sigma_{i}^2)$$

To make use of this assumption, we need to estimate scalars $\mu$ and $\tau^2$ along with the vector $\theta = (\theta_1,\dots,\theta_N)$. We can do this using stan!

```{r}
fit <- stan(file = 'randomEffectsModelConstrainedI.stan', 
            data = basic_dat_generated, 
            iter = 1000, chains = 2)
fit
```
```{r}
# Readjust knowledge of Y based off of REM
params <- extract(fit)
for (i in 1:length(Y$mu)){
  Y$mu[i] <- mean(params$theta[,i])
}
# TODO: Do we need to update the sd at all here post basic fit?
Y
```


### Step 2: Pick $K$ studies to pilot, calculate $Y^P_k$

##### Theoretically

First, pick $K$ studies to update through new information. For these studies, we'll assume a **fixed effects model** and draw a new sample, imagining that this is a new study $Y^p_i$ done in the same place as study $Y_i$, so we can improve on our knowledge of $Y_i$. For now we will arbitrarily decide that $\sigma^P_{i} = \frac 1 5 \sigma_{i}$ (AKA that these new studies done will have a fifth of the error we were encountering in the first study). So for $i \in K$,

$$ Y^P_i \sim N(\theta_i, \frac 1 5 \sigma_{i})$$

##### Concretely

Here we're first going to go with the boring simple version where the subset K is just k=2. So we keep $Y_1$, $Y_3$ unchanged but need to make a $Y'_2$ using the generated $\theta_2$. We use an arbitrary 5x smaller sigma in $Y'_2$ than in $Y_2$ as noted in the norm above
```{r}
# Define set K of cities to try the pilot on and collect more data
# K <- c(2)


# for (k in K){
#   print("Theta for new pilot:")
#   print(Y$mu[k])
#   new_draw <- rnorm( J , mean = Y$mu[k] , sd = (1/5)*Y$sd[k] )
#   print("New Draw Results:")
#   print(new_draw)
# }



```

### Step 3: Update all $Y$ values to get $Y'$

Once those $k$ new values get calculated, update by combining to get 
$$update(Y_k, Y^P_k) = Y'_k$$

This draws on the idea that the mean can be combined with the equation
$$ \mu' = \frac{\mu_2 \sigma_1^2 + \sigma_2^2 \mu_1}{\sigma_2^2 + \sigma_1^2}$$
and variance can be combined using
$$\sigma' = \frac{\sigma_1^2 \sigma_2^2}{\sigma_1^2+\sigma_2^2} = \frac{1}{\frac{1}{\sigma_2^2}+\frac{1}{\sigma_1^2}}$$

##### Concretely 

Now that we have the generated new information $Y^P_k$, we need to combine it with the old information $Y_k$. We can do this by combining the means weighted by their standard deviations.

```{r}
update_Y <- function(mu1, mu2, sigSq1, sigSq2){
  update_mu <- (mu1*sigSq2 + mu2*sigSq1)/(sigSq1 + sigSq2)
  update_sigSq <- (sigSq1*sigSq2)/(sigSq1 + sigSq2)
  return(list(mu = update_mu, sd = update_sigSq))
}

# Calculate new data for all K new pilots
get_pilot_results <- function(K,Y){
  # Before update, Y_P is the same as Y
  Y_P <- Y
  
  # Update for each new pilot k
  for (k in K){
    
    # Gather New Pilot Data
    new_sigmaSq <- Y$sd[k] * (1/5)
    new_mean <- rnorm( 1 , mean = Y$mu[k] , sd = new_sigmaSq )
    
    # Combine the old and new data 
    post_pilot <- update_Y(Y$mu[k],new_mean,Y$sd[k],new_sigmaSq)
    Y_P$mu[k] <- post_pilot$mu
    Y_P$sd[k] <- post_pilot$sd
    return(Y_P)
  }
}

# Y_P <- get_pilot_results(K,Y)
# print("updated Y")
# Y_P
```


### Step 4: Use $Y'$ to get final $\theta'$

and once we have all the updated $Y'_i$ we can use them to get $\theta'_i$ based off of $\mu', \tau'^{2}$ with $Y' \sim N(\theta'_i, \sigma'_{i})$ 

```{r, eval = FALSE}
updated_dat_generated <- list(J, I, Y=Y_P$mu, sigmaSq=Y_P$sd)
fit_updated <- stan(file = 'randomEffectsModelConstrainedI.stan', 
            data = updated_dat_generated, 
            iter = 100, chains = 2, verbose = FALSE)
fit_updated
```
 Now check if this update was worth. How? See if you change your mind.
 Intuitively:
  - see if new prior switches which cities have positive impacts, or see if this changes which cities are in the highest C number of cities
  - So given we can implement in C cities, we 'change our mind' if the top C cites are different in this update than they are in the original prior set.
  - Remember, Y contains the original data, Y_updated has the Y' data.
```{r}
new_ranking <- function(fit_updated,Y_P) {
  params_updated <- extract(fit_updated)
  Y_updated <- Y_P
  for (i in 1:length(Y_updated$mu)){
    Y_updated$mu[i] <- mean(params_updated$theta[,i])
    # TODO: do we update sigma as well??
  }
  new_rank <- order(Y_updated$mu, decreasing=TRUE)
  return(new_rank)
}
```

```{r}
change_mind <- function(K,Y,original_rank){
  Y_P <- get_pilot_results(K,Y)
  updated_dat_generated <- list(J, I, Y=Y_P$mu, sigmaSq=Y_P$sd)
  fit_updated <- stan(file = 'randomEffectsModelConstrainedI.stan', 
                      data = updated_dat_generated, 
                      iter = 1000, chains = 2)
  new_rank <- new_ranking(fit_updated,Y_P) 
  print(new_rank)
  return(!setequal(original_rank[1:D],new_rank[1:D]))
}
```


```{r, results="hide", warning = FALSE}
original_rank <- order(Y$mu, decreasing=TRUE)
original_rank
combinations <-combn(seq(I),C)
nmc <- numeric(I)
for (i in 1:ncol(combinations)){
  for (j in 1:num_hypothetical_draws){
    K <- combinations[,i]
    nmc[i] <- nmc[i] + change_mind(K,Y,original_rank)
  }
} 
nmc
```


Brief summary of the results
```{r}
# So what are these results exactly?
print(Y)
for (i in 1:length(nmc)){
  print(combinations[,i])
  print(paste("Number of times minds changed: ",nmc[i],"/",num_hypothetical_draws))
} 

```


